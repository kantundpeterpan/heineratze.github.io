{"title":"Do students describe professors differently based on gender?","markdown":{"yaml":{"author":"Datacamp & Heiner Atze","theme":"spacelab","title":"Do students describe professors differently based on gender?"},"headingText":"1. Scraping the web for reviews of professors","containsRefs":false,"markdown":"\n\n\n\n\n\n\n\n\n_Note: You can consult the solution of this live training in the file browser as `notebook-solution.ipynb`_\n\nLanguage plays a crucial role in shaping our perceptions and attitudes towards gender in the workplace, in classrooms, and personal relationships. Studies have shown that gender bias in language can have a significant impact on the way people are perceived and treated. \n\nFor example, research has found that job advertisements that use masculine-coded language tend to attract more male applicants, while those that use feminine-coded language tend to attract more female applicants. Similarly, gendered language can perpetuate differences in the classroom.\n\nIn this project, we'll using scraped student reviews from [ratemyprofessors.com](https://ratemyprofessors.com) to identify differences in language commonly used for male vs. female professors, and explore subtleties in how language in the classroom can be gendered.\n\nThis excellent [tool](https://benschmidt.org/profGender/#%7B%22database%22%3A%22RMP%22%2C%22plotType%22%3A%22pointchart%22%2C%22method%22%3A%22return_json%22%2C%22search_limits%22%3A%7B%22word%22%3A%5B%22aggressive%22%5D%2C%22department__id%22%3A%7B%22%24lte%22%3A25%7D%2C%22rHelpful%22%3A%5B1%2C2%5D%2C%22rClarity%22%3A%5B1%2C2%5D%7D%2C%22aesthetic%22%3A%7B%22x%22%3A%22WordsPerMillion%22%2C%22y%22%3A%22department%22%2C%22color%22%3A%22gender%22%7D%2C%22counttype%22%3A%5B%22WordsPerMillion%22%5D%2C%22groups%22%3A%5B%22department%22%2C%22gender%22%5D%2C%22testGroup%22%3A%22C%22%7D) created by Ben Schmidt allows us to enter the words and phrases that we find in our analysis and explore them in more depth. We'll do this at the end.\n\nCatalyst also does some incredible work on [decoding](https://www.catalyst.org/2015/05/07/can-you-spot-the-gender-bias-in-this-job-description/) gendered language.\n\n\nText data‚Äì‚Äìespecially gendered text data, is hard to come by. Web scraping can be a helpful data collection tool when datasets are unable for this kind of work. We can write web scrapers to compile datasets on job descriptions, freelancer reviews, and, as in our use-case, professor reviews by students.\n\n[ratemyprofessors.com](https://www.ratemyprofessors.com/professor?tid=589) provides a wonderful combination of qualitative and quantitative metrics that we can analyze.\n\nAlthough the data on their websites is not labeled by gender, we'll use pronouns used by students to label professors \"Male\" or \"Female\". Of course, this approach is not perfect, as it relies on the _students'_ use of pronouns. Professors with non-binary pronouns will also be under-represented in the data, since very few reviews will have them, and so it's not trivial to write an algorithm to detect them. These are definitely important questions in the world of gender analysis though, so we encourage you to pick them up as extensions of this project!\n\n### Task 1a. What relevant packages do we need for web scraping and reading in data?\n\nlet's see if some text does the trick\n\n### Task 1b. Which professors will we be looking at?\n\nThe `web_scraping.ipynb` notebook provided in this workspace provides some code using selenium that was used to find urls from [ratemyprofessors.com](https://ratemyprofessors.com) that we'll be scraping in this notebook.\n\nWhilst the specific selenium code used to generate this list of URLs is beyond what we can cover today, we encourage you to explore this code to understand how we generated this list of professors!\n\nFor now, we'll open the file `profs_888.txt` and read each professor's url in a new line, and save this variable as `profs`.\n\n### Task 1c. How can we use urls to scrape relevant data about professors?\n\nEach professor has an overall rating that looks like this\n<img src=\"img/overall_rating_example.png\"  width=\"400\">\n\nand a series of reviews that look like this\n![Review example](img/review_example.png)\n\nThe code below can be used to iterate through all or part of the list of urls in `profs`, and scrape them for qualtiative and quantitative data. **You won't need to run through this whole list though, because the `data/` folder already contains the reviews of several professors that we have scraped for you!**\n\n- The overall rating for the professor\n- All the individual reviews written by students about the professor\n- The \"emotion\" corresponding to each individual review: `üòé AWESOME`, `üòê AVERAGE`, or `üòñ AWFUL`\n- A numerical \"quality\" rating corresponding to each individual review\n\nWe won't be using the \"difficulty\" ratings shown here.\n\n# 2. Reading pre-scraped data\n\n### Task 2a. How can we read a directory of scraped professor reviews and concatenate them?\n\nSince we have already scraped reviews from several professors for you, let's begin by concatenating all the files in the `data` folder provided. These have already been scraped for you.\n\nSince `review`, `emotion` and `quality` are lists but were recorded in string form, we'll apply `eval()` to them to turn them back from a string into a list.\n\n### Task 2b. What does the final shape of our DataFrame look like?\n\nBrowse the `df` below to familiarize yourself with the dataset we'll be working with. The DataFrame contains one row for each professor, containing:\n- Their url\n- All the raw text reviews for that professor\n- Their overall rating\n- All the emotion labels associated with reviews of that professor\n- All quality ratings assigned to that professor\n\n# 3. Text Analysis\n\n## 3a. What additional package imports are required for data visualization and NLP?\n\n### 3b. How can we assign gender labels to professors?\n\nLet's write a custom function that assigns a gender label to professors based on the pronouns most commontly used for him. Specifically:\n- If any of `['she', 'her', 'herself', 'shes']` occur more than 5 times across all reviews for that professor, we label the professor \"F\".\n- If any of `['him', 'he', 'his', 'himself']` occur more than 5 times across all reviews for that professor, we label the professor \"F\".\n\n### 3c. Are there any initial differences between male and female professors based on their overall ratings?\n\nLet's start with a barplot.\n\nA boxplot overlaid with a stripplot will give us a better sense of the distribution of the data.\n\n## Task 3d. What are the most important words being used to describe professors in reviews?\n\nLet's write a custom function that **tokenizes** and **lemmatizes** our list of words.\n- **Word tokenization**: process of splitting text into individual words, called tokens. A common preprocessing step in natural language processing (NLP) so that text can be analyzed and processed more easily. Methods include whitespace tokenization, regular expression-based tokenization, and rule-based tokenization. We'll be using the `word_tokenize` tokenizer from `nltk`, with all its defaults.\n- **Lemmatization**: process of reducing words to their base or dictionary form, called the lemma. Also a common pre-processing step in NLP, so that words with a common base form are treated the same way. For example, the lemma of \"am\" is \"be\", of \"running\" is \"run\", and of \"mice\" is \"mouse\".\n\nLet's import a list of stop words, which are common English words that we will be ignoring in our analysis. `sklearn` provides a common list of stop words, and we can append additional words to this list. Below, we append pronouns, along with the words \"class\" and \"student\". Feel free to add any additional words you'd like to ignore to this list later on as you try to build upon this analysis!\n\nFor the purpose of analyzing review texts, we want to move from having one row for each professor to one row for each review. Lets do this with `.explode()` from pandas.\n\nTFIDF vectorization is the process of assigning scores to each review in a document based on how frequently the word occurs, normalized by how frequently the word occurs in the dataset overall.\n\nWe'll use `TfidfVectorizer()` to generate these scores. This will return a matrix, with as many rows as reviews, and as many columns as words in our dataset.\n\n`X` is a sparse matrix. We'll now move into filtering X for:\n- Rows with male professors and reviews of high quality \n- Rows with female professors and reviews of high quality \n- Rows with male professors and reviews of low quality \n- Rows with female professors and reviews of low quality \n\nWe can explore feature importance in each of these to get a sense of which words and phrases are coming up most often in the data.\n\nLet's have a look at what language students are using to describe male professors positively. The code below will return the 300 most important ngrams.\n\nPrint out the 25 most important features\n\nLet's have a look at what language students are using to describe female professors positively.\n\nIt should be interesting if there are words exclusively used for one gender\n\nLet's have a look at what language students are using to describe male professors negatively.\n\nLet's have a look at what language students are using to describe female professors negatively.\n\nSame analysis for exclusive words:\n\n## Congratulations on making it to the end! \n### Where to from here?\n- We can feed these words into Ben Schmidt's [tool](https://benschmidt.org/profGender/#%7B%22database%22%3A%22RMP%22%2C%22plotType%22%3A%22pointchart%22%2C%22method%22%3A%22return_json%22%2C%22search_limits%22%3A%7B%22word%22%3A%5B%22his%20kids%22%2C%22her%20kids%22%5D%2C%22department__id%22%3A%7B%22%24lte%22%3A25%7D%7D%2C%22aesthetic%22%3A%7B%22x%22%3A%22WordsPerMillion%22%2C%22y%22%3A%22department%22%2C%22color%22%3A%22gender%22%7D%2C%22counttype%22%3A%5B%22WordCount%22%2C%22TotalWords%22%5D%2C%22groups%22%3A%5B%22unigram%22%5D%2C%22testGroup%22%3A%22C%22%7D) to derive insights by field.\n- If you're interested in learning more about [web scraping](https://app.datacamp.com/learn/courses/web-scraping-with-python), take our courses on Web Scraping in Python\n- If you're intersted in diving in to the world of Natural Language Processing, explore our [skill track](https://app.datacamp.com/learn/skill-tracks/natural-language-processing-in-python).\n\nUnfortunately Ben Schmidt's tool does not seem to work anymore. So, in order to investigate gender bias in this dataset, I came up with the following research question:\nIs the sentiment of the review associated with the use of stereotypical words for the two genders?\n\nIn order to answer that question, I looked for a lexicon that I could screen the reviews against. While I found some (a lot!) papers addressing detection of gender stereotypes using NLP, I could not find said lexicon - but I foudn that Language Models based on word embeddings also learn the gender bias implicit in the corpus they are trained on.\n\nSo I figured that maybe it would be possible to exploit that to construct - in a quick and dirty kind of fashion - this lexicon myself by asking Google's GEMINI. Some prompt engineering was necessary: [you can have a look for yourself]([url](https://g.co/gemini/share/db15535c30d9)). Ironically, Gemini seemed more hesitant to compile a list of words stereotypically negatively associated with women than for men.\n\nLet's parse those lists:\n","srcMarkdownNoYaml":"\n\n\n\n\n\n\n\n\n_Note: You can consult the solution of this live training in the file browser as `notebook-solution.ipynb`_\n\nLanguage plays a crucial role in shaping our perceptions and attitudes towards gender in the workplace, in classrooms, and personal relationships. Studies have shown that gender bias in language can have a significant impact on the way people are perceived and treated. \n\nFor example, research has found that job advertisements that use masculine-coded language tend to attract more male applicants, while those that use feminine-coded language tend to attract more female applicants. Similarly, gendered language can perpetuate differences in the classroom.\n\nIn this project, we'll using scraped student reviews from [ratemyprofessors.com](https://ratemyprofessors.com) to identify differences in language commonly used for male vs. female professors, and explore subtleties in how language in the classroom can be gendered.\n\nThis excellent [tool](https://benschmidt.org/profGender/#%7B%22database%22%3A%22RMP%22%2C%22plotType%22%3A%22pointchart%22%2C%22method%22%3A%22return_json%22%2C%22search_limits%22%3A%7B%22word%22%3A%5B%22aggressive%22%5D%2C%22department__id%22%3A%7B%22%24lte%22%3A25%7D%2C%22rHelpful%22%3A%5B1%2C2%5D%2C%22rClarity%22%3A%5B1%2C2%5D%7D%2C%22aesthetic%22%3A%7B%22x%22%3A%22WordsPerMillion%22%2C%22y%22%3A%22department%22%2C%22color%22%3A%22gender%22%7D%2C%22counttype%22%3A%5B%22WordsPerMillion%22%5D%2C%22groups%22%3A%5B%22department%22%2C%22gender%22%5D%2C%22testGroup%22%3A%22C%22%7D) created by Ben Schmidt allows us to enter the words and phrases that we find in our analysis and explore them in more depth. We'll do this at the end.\n\nCatalyst also does some incredible work on [decoding](https://www.catalyst.org/2015/05/07/can-you-spot-the-gender-bias-in-this-job-description/) gendered language.\n\n# 1. Scraping the web for reviews of professors\n\nText data‚Äì‚Äìespecially gendered text data, is hard to come by. Web scraping can be a helpful data collection tool when datasets are unable for this kind of work. We can write web scrapers to compile datasets on job descriptions, freelancer reviews, and, as in our use-case, professor reviews by students.\n\n[ratemyprofessors.com](https://www.ratemyprofessors.com/professor?tid=589) provides a wonderful combination of qualitative and quantitative metrics that we can analyze.\n\nAlthough the data on their websites is not labeled by gender, we'll use pronouns used by students to label professors \"Male\" or \"Female\". Of course, this approach is not perfect, as it relies on the _students'_ use of pronouns. Professors with non-binary pronouns will also be under-represented in the data, since very few reviews will have them, and so it's not trivial to write an algorithm to detect them. These are definitely important questions in the world of gender analysis though, so we encourage you to pick them up as extensions of this project!\n\n### Task 1a. What relevant packages do we need for web scraping and reading in data?\n\nlet's see if some text does the trick\n\n### Task 1b. Which professors will we be looking at?\n\nThe `web_scraping.ipynb` notebook provided in this workspace provides some code using selenium that was used to find urls from [ratemyprofessors.com](https://ratemyprofessors.com) that we'll be scraping in this notebook.\n\nWhilst the specific selenium code used to generate this list of URLs is beyond what we can cover today, we encourage you to explore this code to understand how we generated this list of professors!\n\nFor now, we'll open the file `profs_888.txt` and read each professor's url in a new line, and save this variable as `profs`.\n\n### Task 1c. How can we use urls to scrape relevant data about professors?\n\nEach professor has an overall rating that looks like this\n<img src=\"img/overall_rating_example.png\"  width=\"400\">\n\nand a series of reviews that look like this\n![Review example](img/review_example.png)\n\nThe code below can be used to iterate through all or part of the list of urls in `profs`, and scrape them for qualtiative and quantitative data. **You won't need to run through this whole list though, because the `data/` folder already contains the reviews of several professors that we have scraped for you!**\n\n- The overall rating for the professor\n- All the individual reviews written by students about the professor\n- The \"emotion\" corresponding to each individual review: `üòé AWESOME`, `üòê AVERAGE`, or `üòñ AWFUL`\n- A numerical \"quality\" rating corresponding to each individual review\n\nWe won't be using the \"difficulty\" ratings shown here.\n\n# 2. Reading pre-scraped data\n\n### Task 2a. How can we read a directory of scraped professor reviews and concatenate them?\n\nSince we have already scraped reviews from several professors for you, let's begin by concatenating all the files in the `data` folder provided. These have already been scraped for you.\n\nSince `review`, `emotion` and `quality` are lists but were recorded in string form, we'll apply `eval()` to them to turn them back from a string into a list.\n\n### Task 2b. What does the final shape of our DataFrame look like?\n\nBrowse the `df` below to familiarize yourself with the dataset we'll be working with. The DataFrame contains one row for each professor, containing:\n- Their url\n- All the raw text reviews for that professor\n- Their overall rating\n- All the emotion labels associated with reviews of that professor\n- All quality ratings assigned to that professor\n\n# 3. Text Analysis\n\n## 3a. What additional package imports are required for data visualization and NLP?\n\n### 3b. How can we assign gender labels to professors?\n\nLet's write a custom function that assigns a gender label to professors based on the pronouns most commontly used for him. Specifically:\n- If any of `['she', 'her', 'herself', 'shes']` occur more than 5 times across all reviews for that professor, we label the professor \"F\".\n- If any of `['him', 'he', 'his', 'himself']` occur more than 5 times across all reviews for that professor, we label the professor \"F\".\n\n### 3c. Are there any initial differences between male and female professors based on their overall ratings?\n\nLet's start with a barplot.\n\nA boxplot overlaid with a stripplot will give us a better sense of the distribution of the data.\n\n## Task 3d. What are the most important words being used to describe professors in reviews?\n\nLet's write a custom function that **tokenizes** and **lemmatizes** our list of words.\n- **Word tokenization**: process of splitting text into individual words, called tokens. A common preprocessing step in natural language processing (NLP) so that text can be analyzed and processed more easily. Methods include whitespace tokenization, regular expression-based tokenization, and rule-based tokenization. We'll be using the `word_tokenize` tokenizer from `nltk`, with all its defaults.\n- **Lemmatization**: process of reducing words to their base or dictionary form, called the lemma. Also a common pre-processing step in NLP, so that words with a common base form are treated the same way. For example, the lemma of \"am\" is \"be\", of \"running\" is \"run\", and of \"mice\" is \"mouse\".\n\nLet's import a list of stop words, which are common English words that we will be ignoring in our analysis. `sklearn` provides a common list of stop words, and we can append additional words to this list. Below, we append pronouns, along with the words \"class\" and \"student\". Feel free to add any additional words you'd like to ignore to this list later on as you try to build upon this analysis!\n\nFor the purpose of analyzing review texts, we want to move from having one row for each professor to one row for each review. Lets do this with `.explode()` from pandas.\n\nTFIDF vectorization is the process of assigning scores to each review in a document based on how frequently the word occurs, normalized by how frequently the word occurs in the dataset overall.\n\nWe'll use `TfidfVectorizer()` to generate these scores. This will return a matrix, with as many rows as reviews, and as many columns as words in our dataset.\n\n`X` is a sparse matrix. We'll now move into filtering X for:\n- Rows with male professors and reviews of high quality \n- Rows with female professors and reviews of high quality \n- Rows with male professors and reviews of low quality \n- Rows with female professors and reviews of low quality \n\nWe can explore feature importance in each of these to get a sense of which words and phrases are coming up most often in the data.\n\nLet's have a look at what language students are using to describe male professors positively. The code below will return the 300 most important ngrams.\n\nPrint out the 25 most important features\n\nLet's have a look at what language students are using to describe female professors positively.\n\nIt should be interesting if there are words exclusively used for one gender\n\nLet's have a look at what language students are using to describe male professors negatively.\n\nLet's have a look at what language students are using to describe female professors negatively.\n\nSame analysis for exclusive words:\n\n## Congratulations on making it to the end! \n### Where to from here?\n- We can feed these words into Ben Schmidt's [tool](https://benschmidt.org/profGender/#%7B%22database%22%3A%22RMP%22%2C%22plotType%22%3A%22pointchart%22%2C%22method%22%3A%22return_json%22%2C%22search_limits%22%3A%7B%22word%22%3A%5B%22his%20kids%22%2C%22her%20kids%22%5D%2C%22department__id%22%3A%7B%22%24lte%22%3A25%7D%7D%2C%22aesthetic%22%3A%7B%22x%22%3A%22WordsPerMillion%22%2C%22y%22%3A%22department%22%2C%22color%22%3A%22gender%22%7D%2C%22counttype%22%3A%5B%22WordCount%22%2C%22TotalWords%22%5D%2C%22groups%22%3A%5B%22unigram%22%5D%2C%22testGroup%22%3A%22C%22%7D) to derive insights by field.\n- If you're interested in learning more about [web scraping](https://app.datacamp.com/learn/courses/web-scraping-with-python), take our courses on Web Scraping in Python\n- If you're intersted in diving in to the world of Natural Language Processing, explore our [skill track](https://app.datacamp.com/learn/skill-tracks/natural-language-processing-in-python).\n\nUnfortunately Ben Schmidt's tool does not seem to work anymore. So, in order to investigate gender bias in this dataset, I came up with the following research question:\nIs the sentiment of the review associated with the use of stereotypical words for the two genders?\n\nIn order to answer that question, I looked for a lexicon that I could screen the reviews against. While I found some (a lot!) papers addressing detection of gender stereotypes using NLP, I could not find said lexicon - but I foudn that Language Models based on word embeddings also learn the gender bias implicit in the corpus they are trained on.\n\nSo I figured that maybe it would be possible to exploit that to construct - in a quick and dirty kind of fashion - this lexicon myself by asking Google's GEMINI. Some prompt engineering was necessary: [you can have a look for yourself]([url](https://g.co/gemini/share/db15535c30d9)). Ironically, Gemini seemed more hesitant to compile a list of words stereotypically negatively associated with women than for men.\n\nLet's parse those lists:\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"notebook.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.54","theme":"spacelab","author":"Datacamp & Heiner Atze","title":"Do students describe professors differently based on gender?"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}