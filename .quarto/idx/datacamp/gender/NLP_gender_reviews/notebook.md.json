{"title":"Do students describe professors differently based on gender?","markdown":{"headingText":"Do students describe professors differently based on gender?","containsRefs":false,"markdown":"::: {#8d666ddc .cell .markdown}\n\n------------------------------------------------------------------------\n\nauthor: Datacamp & Heiner Atze markdown-headings: setext code-fold: true\ntheme: spacelab \\-\\--\n:::\n\n::: {#14a7a4ee-8d58-46f3-ad0b-d79f48726c90 .cell .markdown}\n:::\n\n::: {#ea79ab00-9335-48d5-9fa9-216776459af9 .cell .markdown}\n*Note: You can consult the solution of this live training in the file\nbrowser as `notebook-solution.ipynb`*\n\nLanguage plays a crucial role in shaping our perceptions and attitudes\ntowards gender in the workplace, in classrooms, and personal\nrelationships. Studies have shown that gender bias in language can have\na significant impact on the way people are perceived and treated.\n\nFor example, research has found that job advertisements that use\nmasculine-coded language tend to attract more male applicants, while\nthose that use feminine-coded language tend to attract more female\napplicants. Similarly, gendered language can perpetuate differences in\nthe classroom.\n\nIn this project, we\\'ll using scraped student reviews from\n[ratemyprofessors.com](https://ratemyprofessors.com) to identify\ndifferences in language commonly used for male vs. female professors,\nand explore subtleties in how language in the classroom can be gendered.\n\nThis excellent\n[tool](https://benschmidt.org/profGender/#%7B%22database%22%3A%22RMP%22%2C%22plotType%22%3A%22pointchart%22%2C%22method%22%3A%22return_json%22%2C%22search_limits%22%3A%7B%22word%22%3A%5B%22aggressive%22%5D%2C%22department__id%22%3A%7B%22%24lte%22%3A25%7D%2C%22rHelpful%22%3A%5B1%2C2%5D%2C%22rClarity%22%3A%5B1%2C2%5D%7D%2C%22aesthetic%22%3A%7B%22x%22%3A%22WordsPerMillion%22%2C%22y%22%3A%22department%22%2C%22color%22%3A%22gender%22%7D%2C%22counttype%22%3A%5B%22WordsPerMillion%22%5D%2C%22groups%22%3A%5B%22department%22%2C%22gender%22%5D%2C%22testGroup%22%3A%22C%22%7D)\ncreated by Ben Schmidt allows us to enter the words and phrases that we\nfind in our analysis and explore them in more depth. We\\'ll do this at\nthe end.\n\nCatalyst also does some incredible work on\n[decoding](https://www.catalyst.org/2015/05/07/can-you-spot-the-gender-bias-in-this-job-description/)\ngendered language.\n:::\n\n::: {#ba20f3ce-5247-49ba-9779-31786362fcbb .cell .markdown tags=\"[]\"}\n# 1. Scraping the web for reviews of professors {#1-scraping-the-web-for-reviews-of-professors}\n:::\n\n::: {#f6e0f772-1772-43e5-a373-be16b17595dc .cell .markdown}\nText data----especially gendered text data, is hard to come by. Web\nscraping can be a helpful data collection tool when datasets are unable\nfor this kind of work. We can write web scrapers to compile datasets on\njob descriptions, freelancer reviews, and, as in our use-case, professor\nreviews by students.\n\n[ratemyprofessors.com](https://www.ratemyprofessors.com/professor?tid=589)\nprovides a wonderful combination of qualitative and quantitative metrics\nthat we can analyze.\n\nAlthough the data on their websites is not labeled by gender, we\\'ll use\npronouns used by students to label professors \\\"Male\\\" or \\\"Female\\\". Of\ncourse, this approach is not perfect, as it relies on the *students\\'*\nuse of pronouns. Professors with non-binary pronouns will also be\nunder-represented in the data, since very few reviews will have them,\nand so it\\'s not trivial to write an algorithm to detect them. These are\ndefinitely important questions in the world of gender analysis though,\nso we encourage you to pick them up as extensions of this project!\n:::\n\n::: {#ccd150d6-5aae-4ebf-86f5-d8b398694e99 .cell .markdown}\n### Task 1a. What relevant packages do we need for web scraping and reading in data? {#task-1a-what-relevant-packages-do-we-need-for-web-scraping-and-reading-in-data}\n\nlet\\'s see if some text does the trick\n:::\n\n::: {#5d32b671-a5a9-4b1c-b730-dbd276406a93 .cell .code execution_count=\"1\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"31\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766529332\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"# Used to open urls\nimport requests\n\n# Used to parse html\nfrom lxml import etree\n\n# Used to pause code intermittently so that our scraper is not blocked\nimport time\n\n# For data manipulation and analysis\nimport pandas as pd\n\n# To access our data filenames so we can read them\nimport os\"}\n``` python\nimport requests\n\n# Used to parse html\nfrom lxml import etree\n\n# Used to pause code intermittently so that our scraper is not blocked\nimport time\n\n# For data manipulation and analysis\nimport pandas as pd\n\n# To access our data filenames so we can read them\nimport os\n```\n:::\n\n::: {#7a97cd1a-5f8b-489b-b403-eb56cdffb44a .cell .markdown}\n### Task 1b. Which professors will we be looking at? {#task-1b-which-professors-will-we-be-looking-at}\n:::\n\n::: {#be2fb34c-3bb1-4f97-91a6-dd4eb826d85b .cell .markdown}\nThe `web_scraping.ipynb` notebook provided in this workspace provides\nsome code using selenium that was used to find urls from\n[ratemyprofessors.com](https://ratemyprofessors.com) that we\\'ll be\nscraping in this notebook.\n\nWhilst the specific selenium code used to generate this list of URLs is\nbeyond what we can cover today, we encourage you to explore this code to\nunderstand how we generated this list of professors!\n\nFor now, we\\'ll open the file `profs_888.txt` and read each professor\\'s\nurl in a new line, and save this variable as `profs`.\n:::\n\n::: {#83b8efe1-4c75-4755-9534-a8889b82c6d6 .cell .code execution_count=\"2\" executionCancelledAt=\"null\" executionTime=\"180\" lastExecutedAt=\"1719766529512\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"with open(r'profs_1244.txt', 'r') as f:\n    profs = [x.strip() for x in f.readlines()]\" tags=\"[]\"}\n``` python\nwith open(r'profs_1244.txt', 'r') as f:\n    profs = [x.strip() for x in f.readlines()]\n```\n:::\n\n::: {#22e4d4d2-d11a-44a1-95bd-f03b37f1fcc4 .cell .code execution_count=\"3\" executionCancelledAt=\"null\" executionTime=\"52\" lastExecutedAt=\"1719766529566\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"profs[0]\"}\n``` python\nprofs[0]\n```\n\n::: {.output .execute_result execution_count=\"3\"}\n    'https://www.ratemyprofessors.com/professor?tid=398'\n:::\n:::\n\n::: {#9802615b-401c-4c7a-b179-384d390ccbe1 .cell .markdown}\n### Task 1c. How can we use urls to scrape relevant data about professors? {#task-1c-how-can-we-use-urls-to-scrape-relevant-data-about-professors} \\\n:::\n\n::: {#2f8e77b9-980a-494a-a652-a9f27c3a3659 .cell .markdown}\n `<img src=\"img/overall_rating_example.png\"  width=\"400\">`{=html} \n\n\n\nEach professor has an overall rating that looks like this\nand a series of reviews that look like this ![Reviewexample](img/review_example.png)\n\nThe code below can be used to iterate through all or part of the list of\nurls in `profs`, and scrape them for qualtiative and quantitative data.\n**You won\\'t need to run through this whole list though, because the\n`data/` folder already contains the reviews of several professors that\nwe have scraped for you!**\n\n-   The overall rating for the professor\n-   All the individual reviews written by students about the professor\n-   The \\\"emotion\\\" corresponding to each individual review:\n    `üòé AWESOME`, `üòê AVERAGE`, or `üòñ AWFUL`\n-   A numerical \\\"quality\\\" rating corresponding to each individual\n    review\n\nWe won\\'t be using the \\\"difficulty\\\" ratings shown here.\n:::\n\n::: {#68bb1e9b-dbda-45fe-8ba3-ba3d8110d3eb .cell .code execution_count=\"4\" executionCancelledAt=\"null\" executionTime=\"54\" lastExecutedAt=\"1719766529620\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"from io import StringIO\"}\n``` python\nfrom io import StringIO\n```\n:::\n\n::: {#9fc15814-5c07-4691-a9f3-76e0d73e3030 .cell .code execution_count=\"5\" executionCancelledAt=\"null\" executionTime=\"47\" lastExecutedAt=\"1719766529668\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"import numpy as np\"}\n``` python\nimport numpy as np\n```\n:::\n\n::: {#432d6789-8153-4de1-baae-ae211ca49c23 .cell .code execution_count=\"6\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"36228\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766565897\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"# USE ONLY ONE OF THE FOLLOWING FOR STATWEMENTS\n\n# 1. Sample code to loop through the whole list of professors    \n# for s in (range(40, len(profs),10)):\n\n# 2. Sample code to loop through the first 10 professors\nfor s in range(0,10,10):\n\n    texts = [] # Initialzie an empty array\n    print((s, s+10)) # Iterate through 10 professors at a time\n    \n    for url in profs[s:s+10]: # Iterate through this block\n        time.sleep(3) # To prevent sending too many requests at once\n        r = requests.get(url) # Open URL\n        htmlparser = etree.HTMLParser() # Instantiate a parser to parse HTML\n        tree = etree.parse(StringIO(r.text), htmlparser) # Parse HTML returned by the url\n        \n        text = tree.xpath('//*[@id=\\\"ratingsList\\\"]/li[*]/div/div/div[3]/div[3]/text()') # Extract reviews\n        ratings = tree.xpath('//*[@id=\\\"root\\\"]/div/div/div[3]/div[2]/div[1]/div[1]/div[1]/div/div[1]') # Extract ratings\n        emotion = tree.xpath('//*[@id=\\\"ratingsList\\\"]/li[*]/div/div/div[1]/div[1]/div[2]/text()') # Extract emotion\n        quality = tree.xpath('//*[@id=\\\"ratingsList\\\"]/li[*]/div/div/div[2]/div[1]/div/div[2]') # Extract quality\n        texts.append((url,\n                      text,\n                      [i.text for i in ratings][0],\n                      emotion,\n                      [i.text for i in quality],\n                     )) # Append metrics to empty list\n\n    print() # Print new line for readability\n    df = pd.DataFrame(texts, columns = ['url', 'review', 'rating', 'emtion', 'quality'])\n    df.to_csv(f'df_{s}_to_{s+10}.csv') # Write result to df in blocks of 10 professors at a time\n    time.sleep(3) # Pause to prevent sending too many requests at once\" outputsMetadata=\"{\\\"0\\\":{\\\"height\\\":59,\\\"type\\\":\\\"stream\\\"}}\"}\n``` python\n# USE ONLY ONE OF THE FOLLOWING FOR STATWEMENTS\n\n# 1. Sample code to loop through the whole list of professors    \n# for s in (range(40, len(profs),10)):\n\n# 2. Sample code to loop through the first 10 professors\nfor s in range(0,10,10):\n\n    texts = [] # Initialzie an empty array\n    print((s, s+10)) # Iterate through 10 professors at a time\n    \n    for url in profs[s:s+10]: # Iterate through this block\n        time.sleep(3) # To prevent sending too many requests at once\n        r = requests.get(url) # Open URL\n        htmlparser = etree.HTMLParser() # Instantiate a parser to parse HTML\n        tree = etree.parse(StringIO(r.text), htmlparser) # Parse HTML returned by the url\n        \n        text = tree.xpath('//*[@id=\"ratingsList\"]/li[*]/div/div/div[3]/div[3]/text()') # Extract reviews\n        ratings = tree.xpath('//*[@id=\"root\"]/div/div/div[3]/div[2]/div[1]/div[1]/div[1]/div/div[1]') # Extract ratings\n        emotion = tree.xpath('//*[@id=\"ratingsList\"]/li[*]/div/div/div[1]/div[1]/div[2]/text()') # Extract emotion\n        quality = tree.xpath('//*[@id=\"ratingsList\"]/li[*]/div/div/div[2]/div[1]/div/div[2]') # Extract quality\n        texts.append((url,\n                      text,\n                      [i.text for i in ratings][0],\n                      emotion,\n                      [i.text for i in quality],\n                     )) # Append metrics to empty list\n\n    print() # Print new line for readability\n    df = pd.DataFrame(texts, columns = ['url', 'review', 'rating', 'emtion', 'quality'])\n    df.to_csv(f'df_{s}_to_{s+10}.csv') # Write result to df in blocks of 10 professors at a time\n    time.sleep(3) # Pause to prevent sending too many requests at once\n```\n\n::: {.output .stream .stdout}\n    (0, 10)\n:::\n:::\n\n::: {#107e3b3a-1673-497d-bff8-dca84520018a .cell .markdown tags=\"[]\"}\n# 2. Reading pre-scraped data {#2-reading-pre-scraped-data}\n:::\n\n::: {#109b0595-0ccd-47e0-9a20-adda21d7a769 .cell .markdown}\n### Task 2a. How can we read a directory of scraped professor reviews and concatenate them? {#task-2a-how-can-we-read-a-directory-of-scraped-professor-reviews-and-concatenate-them}\n:::\n\n::: {#2a2fe127-441b-4453-ac3b-569b24cd85d5 .cell .markdown}\nSince we have already scraped reviews from several professors for you,\nlet\\'s begin by concatenating all the files in the `data` folder\nprovided. These have already been scraped for you.\n\nSince `review`, `emotion` and `quality` are lists but were recorded in\nstring form, we\\'ll apply `eval()` to them to turn them back from a\nstring into a list.\n:::\n\n::: {#00a06042-4be0-4c2e-967c-68a0664d55b1 .cell .code execution_count=\"7\" executionCancelledAt=\"null\" executionTime=\"50\" lastExecutedAt=\"1719766565948\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"from glob import glob\"}\n``` python\nfrom glob import glob\n```\n:::\n\n::: {#8d0eb371-f339-4c0a-b3e2-0a5840af2706 .cell .code execution_count=\"8\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"2848\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766568797\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"df = pd.concat([pd.read_csv(x, index_col=0) for x in glob('data/*.csv')]).reset_index(drop = True)\ndf['review'] = df['review'].apply(lambda x: eval(x))\ndf['emotion'] = df['emotion'].apply(lambda x: eval(x))\ndf['quality'] = df['quality'].apply(lambda x: eval(x))\"}\n``` python\ndf = pd.concat([pd.read_csv(x, index_col=0) for x in glob('data/*.csv')]).reset_index(drop = True)\ndf['review'] = df['review'].apply(lambda x: eval(x))\ndf['emotion'] = df['emotion'].apply(lambda x: eval(x))\ndf['quality'] = df['quality'].apply(lambda x: eval(x))\n```\n:::\n\n::: {#3700fde1-0644-4208-8bd5-f2272482d31e .cell .markdown}\n### Task 2b. What does the final shape of our DataFrame look like? {#task-2b-what-does-the-final-shape-of-our-dataframe-look-like}\n:::\n\n::: {#47b377de-594c-46c2-8bd8-4af9a0eddc00 .cell .markdown}\nBrowse the `df` below to familiarize yourself with the dataset we\\'ll be\nworking with. The DataFrame contains one row for each professor,\ncontaining:\n\n-   Their url\n-   All the raw text reviews for that professor\n-   Their overall rating\n-   All the emotion labels associated with reviews of that professor\n-   All quality ratings assigned to that professor\n:::\n\n::: {#33dbb820-d76a-4607-96f3-0ff3859c0e6b .cell .code execution_count=\"9\" executionCancelledAt=\"null\" executionTime=\"178\" lastExecutedAt=\"1719766568977\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"df\" outputsMetadata=\"{\\\"0\\\":{\\\"height\\\":321,\\\"type\\\":\\\"dataFrame\\\"}}\"}\n``` python\ndf\n```\n\n::: {.output .execute_result execution_count=\"9\"}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prof</th>\n      <th>review</th>\n      <th>rating</th>\n      <th>emotion</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[Good experience for a class online. It was un...</td>\n      <td>3.1</td>\n      <td>[awesome, awful, awful, awful, average, awful,...</td>\n      <td>[4.0, 2.0, 1.0, 1.0, 3.0, 2.5, 1.5, 2.0, 2.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[I used to like Geography before I took Ali. G...</td>\n      <td>3.1</td>\n      <td>[awful, average, awful, awful, awful, average,...</td>\n      <td>[2.5, 3.5, 2.5, 2.5, 2.0, 3.0, 4.5, 4.5, 4.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[She was a good professor. It was a pass/fail ...</td>\n      <td>3.9</td>\n      <td>[awesome, awesome, awesome, awesome, awesome, ...</td>\n      <td>[5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 1.5, 5.0, 1.5, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[Writing 104 with someone else is the class yo...</td>\n      <td>2.0</td>\n      <td>[awful, awesome, awful, awful, awful, awesome,...</td>\n      <td>[1.0, 4.0, 1.0, 1.0, 1.5, 4.0, 2.0, 2.0, 4.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[Honestly, this guy is great. I took him a few...</td>\n      <td>4.1</td>\n      <td>[awesome, average, awesome, awesome, awesome, ...</td>\n      <td>[5.0, 3.0, 4.5, 5.0, 4.0, 5.0, 4.5, 2.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>575</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[This is one of the better profs at CSUSB. I s...</td>\n      <td>2.6</td>\n      <td>[average, awful, awesome, awful, awesome, awfu...</td>\n      <td>[3.0, 1.0, 4.0, 1.0, 4.0, 1.0, 1.0, 4.0, 3.0, ...</td>\n    </tr>\n    <tr>\n      <th>576</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[His class is extremely hard. I usually make v...</td>\n      <td>2.8</td>\n      <td>[awful, awful, awful, awful, awful, awesome, a...</td>\n      <td>[1.0, 1.0, 1.0, 2.0, 1.5, 4.5, 2.0, 3.0, 5.0, ...</td>\n    </tr>\n    <tr>\n      <th>577</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[(Chem 8) Prides himself on being a \"fair\" pro...</td>\n      <td>3.1</td>\n      <td>[awful, awesome, average, awesome, average, aw...</td>\n      <td>[1.0, 5.0, 3.5, 4.0, 3.0, 2.5, 3.0, 3.5, 4.0, ...</td>\n    </tr>\n    <tr>\n      <th>578</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[I had him back in 1980!  Some things never ch...</td>\n      <td>3.6</td>\n      <td>[average, awesome, awful, awesome, awesome, av...</td>\n      <td>[3.0, 4.0, 2.5, 4.0, 5.0, 3.5, 2.5, 4.5, 4.5, ...</td>\n    </tr>\n    <tr>\n      <th>579</th>\n      <td>https://www.ratemyprofessors.com/professor?tid...</td>\n      <td>[She is the worst teacher to have. I had her a...</td>\n      <td>3.4</td>\n      <td>[awful, awful, awesome, average, awful, awful,...</td>\n      <td>[1.0, 1.0, 4.0, 3.5, 2.0, 1.0, 3.5, 3.5, 1.5, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>580 rows √ó 5 columns</p>\n</div>\n```\n:::\n:::\n\n::: {#683c95fb-8fa5-4278-9401-55132918db3e .cell .markdown tags=\"[]\"}\n# 3. Text Analysis {#3-text-analysis}\n:::\n\n::: {#f784a6d5-7980-494d-a169-00579322eeae .cell .markdown}\n## 3a. What additional package imports are required for data visualization and NLP? {#3a-what-additional-package-imports-are-required-for-data-visualization-and-nlp}\n:::\n\n::: {#8d6a7a01-887d-4df1-98b6-5a3c95e35519 .cell .code execution_count=\"10\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"1184\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766570161\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"import numpy as np # For manipulating matrices during NLP\n\nimport nltk # Natural language toolkit\nfrom nltk.tokenize import word_tokenize # Used for breaking up strings of text (e.g. sentences) into words\nfrom nltk.stem.porter import PorterStemmer # Used to return the dictionary base of a word\nfrom nltk.tokenize import WhitespaceTokenizer # Used for breaking up strings of text (e.g. sentences) into words based on white space\n\nnltk.download('punkt')\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # Used to count the occurences of words and phrases\nfrom sklearn.feature_extraction import text # Using to extrat features from text\n\n# For plotting\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style='white')\" outputsMetadata=\"{\\\"0\\\":{\\\"height\\\":59,\\\"type\\\":\\\"stream\\\"}}\"}\n``` python\nimport numpy as np # For manipulating matrices during NLP\n\nimport nltk # Natural language toolkit\nfrom nltk.tokenize import word_tokenize # Used for breaking up strings of text (e.g. sentences) into words\nfrom nltk.stem.porter import PorterStemmer # Used to return the dictionary base of a word\nfrom nltk.tokenize import WhitespaceTokenizer # Used for breaking up strings of text (e.g. sentences) into words based on white space\n\nnltk.download('punkt')\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # Used to count the occurences of words and phrases\nfrom sklearn.feature_extraction import text as sktext# Using to extrat features from text\n\n# For plotting\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style='white')\n```\n\n::: {.output .stream .stderr}\n    [nltk_data] Downloading package punkt to\n    [nltk_data]     /home/kantundpeterpan/nltk_data...\n    [nltk_data]   Package punkt is already up-to-date!\n:::\n:::\n\n::: {#3f712991-c01a-40b1-93e0-34d3f22969b3 .cell .markdown}\n### 3b. How can we assign gender labels to professors? {#3b-how-can-we-assign-gender-labels-to-professors}\n:::\n\n::: {#75750667-fe53-4a54-a79d-4ae4432c3e08 .cell .markdown}\nLet\\'s write a custom function that assigns a gender label to professors\nbased on the pronouns most commontly used for him. Specifically:\n\n-   If any of `['she', 'her', 'herself', 'shes']` occur more than 5\n    times across all reviews for that professor, we label the professor\n    \\\"F\\\".\n-   If any of `['him', 'he', 'his', 'himself']` occur more than 5 times\n    across all reviews for that professor, we label the professor \\\"F\\\".\n:::\n\n::: {#507d2c12-93f3-4a14-96a6-b6cd95c5976c .cell .code execution_count=\"11\" executionCancelledAt=\"null\" executionTime=\"58\" lastExecutedAt=\"1719766570220\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"from collections import Counter\"}\n``` python\nfrom collections import Counter\n```\n:::\n\n::: {#b44c0b61-91e6-4a2e-b969-8e12d9dca25e .cell .code execution_count=\"12\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"47\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766570268\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"def assign_pronoun(review_list):\n    \n    she_ps = ['she', 'her', 'herself', 'shes']\n    he_ps = ['him', 'he', 'his', 'himself']\n    \n    counters = [Counter(word_tokenize(r.lower())) for r in review_list]\n    \n    ### FEMALE\n    she_ps_counter = dict()\n    \n    for sp in she_ps:\n        she_ps_counter[sp] = 0\n        she_ps_counter[sp] = sum([c[sp] if sp in c.keys() else 0 for c in counters])\n        \n    she_ps_counts = np.array([she_ps_counter[sp] for sp in she_ps])\n    \n    if np.sum(she_ps_counts) > 5:\n        return \\\"F\\\"\n    \n    ### MALE\n    he_ps_counter = dict()\n    \n    for hp in he_ps:\n        he_ps_counter[hp] = 0\n        he_ps_counter[hp] = sum([c[hp] if hp in c.keys() else 0 for c in counters])\n        \n    he_ps_counts = np.array([he_ps_counter[hp] for hp in he_ps])\n    \n    if np.sum(he_ps_counts) > 5:\n        return \\\"M\\\"\"}\n``` python\ndef assign_pronoun(review_list):\n    \n    she_ps = ['she', 'her', 'herself', 'shes']\n    he_ps = ['him', 'he', 'his', 'himself']\n    \n    counters = [Counter(word_tokenize(r.lower())) for r in review_list]\n    \n    ### FEMALE\n    she_ps_counter = dict()\n    \n    for sp in she_ps:\n        she_ps_counter[sp] = 0\n        she_ps_counter[sp] = sum([c[sp] if sp in c.keys() else 0 for c in counters])\n        \n    she_ps_counts = np.array([she_ps_counter[sp] for sp in she_ps])\n    \n    if np.sum(she_ps_counts) > 5:\n        return \"F\"\n    \n    ### MALE\n    he_ps_counter = dict()\n    \n    for hp in he_ps:\n        he_ps_counter[hp] = 0\n        he_ps_counter[hp] = sum([c[hp] if hp in c.keys() else 0 for c in counters])\n        \n    he_ps_counts = np.array([he_ps_counter[hp] for hp in he_ps])\n    \n    if np.sum(he_ps_counts) > 5:\n        return \"M\"\n```\n:::\n\n::: {#051288f7-17ac-448b-9fe9-43f5d3f133ec .cell .code execution_count=\"13\" executionCancelledAt=\"null\" executionTime=\"48\" lastExecutedAt=\"1719766570316\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"assign_pronoun(df.review.iloc[6])\" outputsMetadata=\"{\\\"0\\\":{\\\"height\\\":101,\\\"type\\\":\\\"stream\\\"}}\"}\n``` python\nassign_pronoun(df.review.iloc[6])\n```\n\n::: {.output .execute_result execution_count=\"13\"}\n    'M'\n:::\n:::\n\n::: {#ceafc103-6ee0-4d16-a61c-aadbf489900c .cell .code execution_count=\"14\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"3308\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766573624\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"df['pronouns'] = df.review.apply(assign_pronoun)\"}\n``` python\ndf['pronouns'] = df.review.apply(assign_pronoun)\n```\n:::\n\n::: {#36558614-c9ea-44d5-b25a-84cd8313cb88 .cell .code execution_count=\"15\" executionCancelledAt=\"null\" executionTime=\"51\" lastExecutedAt=\"1719766573677\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"df.pronouns.value_counts()\" outputsMetadata=\"{\\\"0\\\":{\\\"height\\\":121,\\\"type\\\":\\\"dataFrame\\\"}}\"}\n``` python\ndf.pronouns.value_counts()\n```\n\n::: {.output .execute_result execution_count=\"15\"}\n    pronouns\n    M    417\n    F    139\n    Name: count, dtype: int64\n:::\n:::\n\n::: {#b5855d24-939a-4b8e-8fa5-43d33484e215 .cell .markdown}\n### 3c. Are there any initial differences between male and female professors based on their overall ratings? {#3c-are-there-any-initial-differences-between-male-and-female-professors-based-on-their-overall-ratings}\n:::\n\n::: {#9e9ebb76-8772-4a96-9568-29b6d4b31854 .cell .markdown}\nLet\\'s start with a barplot.\n:::\n\n::: {#d839f267-6424-4f91-9753-6f14741947e8 .cell .code execution_count=\"16\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"428\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766574105\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"plt.figure(figsize=(4,4))\nsns.barplot(df, x = 'pronouns', y = 'rating', estimator = 'median',\n            palette = 'magma')\nplt.show()\"}\n``` python\nplt.figure(figsize=(4,4))\nsns.barplot(data = df, x = 'pronouns', y = 'rating', estimator = 'median',\n            palette = 'magma')\nplt.show()\n```\n\n::: {.output .stream .stderr}\n    /tmp/ipykernel_1296108/2203816405.py:2: FutureWarning: \n\n    Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n      sns.barplot(data = df, x = 'pronouns', y = 'rating', estimator = 'median',\n:::\n\n::: {.output .display_data}\n![](3c9b228fa2f64c3be916615651d0183e349b2957.png)\n:::\n:::\n\n::: {#201d7abd-6bfb-4331-b302-aae759c825b6 .cell .markdown}\nA boxplot overlaid with a stripplot will give us a better sense of the\ndistribution of the data.\n:::\n\n::: {#171c79c8-f16b-43c7-9692-5123a609d72e .cell .code execution_count=\"17\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"262\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766574367\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"plt.figure(figsize=(5,5))\nsns.boxplot(df, x = 'pronouns', y = 'rating', palette = 'magma')\nsns.stripplot(df, x = 'pronouns', y = 'rating', jitter = 0.2, color = 'lightblue',\n              edgecolor = 'k', linewidth=1)\nplt.show()\"}\n``` python\nplt.figure(figsize=(5,5))\nsns.boxplot(df, x = 'pronouns', y = 'rating', palette = 'magma')\nsns.stripplot(data = df, x = 'pronouns', y = 'rating', jitter = 0.2, color = 'lightblue',\n              edgecolor = 'k', linewidth=1)\nplt.show()\n```\n\n::: {.output .stream .stderr}\n    /tmp/ipykernel_1296108/1838852018.py:2: FutureWarning: \n\n    Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n      sns.boxplot(df, x = 'pronouns', y = 'rating', palette = 'magma')\n:::\n\n::: {.output .display_data}\n![](dea75d0dc03b07ac8c6c2b79a1f186b7057cb6d4.png)\n:::\n:::\n\n::: {#bff5534f-7399-4c52-9544-d1f82b100f44 .cell .markdown}\n## Task 3d. What are the most important words being used to describe professors in reviews? {#task-3d-what-are-the-most-important-words-being-used-to-describe-professors-in-reviews}\n:::\n\n::: {#10b0a53e-8354-4335-9ce7-ff4ca427dc26 .cell .markdown}\nLet\\'s write a custom function that **tokenizes** and **lemmatizes** our\nlist of words.\n\n-   **Word tokenization**: process of splitting text into individual\n    words, called tokens. A common preprocessing step in natural\n    language processing (NLP) so that text can be analyzed and processed\n    more easily. Methods include whitespace tokenization, regular\n    expression-based tokenization, and rule-based tokenization. We\\'ll\n    be using the `word_tokenize` tokenizer from `nltk`, with all its\n    defaults.\n-   **Lemmatization**: process of reducing words to their base or\n    dictionary form, called the lemma. Also a common pre-processing step\n    in NLP, so that words with a common base form are treated the same\n    way. For example, the lemma of \\\"am\\\" is \\\"be\\\", of \\\"running\\\" is\n    \\\"run\\\", and of \\\"mice\\\" is \\\"mouse\\\".\n:::\n\n::: {#d9446182-ac3e-4346-8d0d-3538fb39de7f .cell .code execution_count=\"18\"}\n``` python\nPorterStemmer().stem(\"she\\'s\")\n```\n\n::: {.output .execute_result execution_count=\"18\"}\n    \"she'\"\n:::\n:::\n\n::: {#8d2ad9b7-22b1-42ff-910d-c242e4ed2756 .cell .code execution_count=\"19\"}\n``` python\nword_tokenize('she\\'s a girl')\n```\n\n::: {.output .execute_result execution_count=\"19\"}\n    ['she', \"'s\", 'a', 'girl']\n:::\n:::\n\n::: {#db3dfce9-6056-404c-a5b0-18ac4c0205f8 .cell .code execution_count=\"20\"}\n``` python\nimport string\n```\n:::\n\n::: {#14af1c53-1fae-4673-b8a9-c80945fcf6b0 .cell .code execution_count=\"21\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"53\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766574420\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"def tokenize(text):\n    tk = WhitespaceTokenizer()\n    tokens = tk.tokenize(text)\n    stems = []\n    for item in tokens:\n        stems.append(PorterStemmer().stem(item))\n    return stems\"}\n``` python\ndef tokenize(text):\n    tk = WhitespaceTokenizer()\n    tokens = tk.tokenize(text)\n    stems = []\n    for item in tokens:\n        stems.append(PorterStemmer().stem(item).strip(string.punctuation))\n    return stems\n```\n:::\n\n::: {#54e5a342-e573-4989-9139-9da1125c7612 .cell .markdown}\nLet\\'s import a list of stop words, which are common English words that\nwe will be ignoring in our analysis. `sklearn` provides a common list of\nstop words, and we can append additional words to this list. Below, we\nappend pronouns, along with the words \\\"class\\\" and \\\"student\\\". Feel\nfree to add any additional words you\\'d like to ignore to this list\nlater on as you try to build upon this analysis!\n:::\n\n::: {#17fee0ae-b095-4132-b09b-f06bf8dda71b .cell .code execution_count=\"22\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"47\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766574468\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"my_stop_words = text.ENGLISH_STOP_WORDS.union([\\\"he\\\",\\\"she\\\",\\\"his\\\",\\\"her\\\",\n                                              \\\"himself\\\",\\\"herself\\\", \\\"hers\\\",\\\"shes\\\"\n                                              \\\"class\\\",\\\"student\\\"])\"}\n``` python\nmy_stop_words = sktext.ENGLISH_STOP_WORDS.union([\"he\",\"she\",\"his\",\"her\",\n                                              \"himself\",\"herself\", \"hers\",\"shes\"\n                                              \"class\",\"student\", 'man', 'woman', 'girl',\n                                                 'guy', 'lady', 'mr', 'mrs', 'ms'])\nmy_stop_words = my_stop_words.union([tokenize(word)[0] for word in my_stop_words])\n```\n:::\n\n::: {#cf24febc-27d7-4c84-910c-9118ea6832fa .cell .markdown}\nFor the purpose of analyzing review texts, we want to move from having\none row for each professor to one row for each review. Lets do this with\n`.explode()` from pandas.\n:::\n\n::: {#91f24d99-a96d-4a6b-8f19-b972aac0885f .cell .code execution_count=\"23\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"59\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766574528\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"df_quality = df[(df['review'].apply(len) == df['quality'].apply(len))]\nq = df_quality[['pronouns','review','quality']].explode(['review','quality'], ignore_index=True).dropna()\nq['quality'] = q['quality'].astype(float)\"}\n``` python\ndf_quality = df[(df['review'].apply(len) == df['quality'].apply(len))]\nq = df_quality[['pronouns','review','quality']].explode(['review','quality'], ignore_index=True).dropna()\nq['quality'] = q['quality'].astype(float)\n```\n:::\n\n::: {#0f1c3778-4b39-4bf5-a86e-eb9f07f12976 .cell .code execution_count=\"24\" executionCancelledAt=\"null\" executionTime=\"60\" lastExecutedAt=\"1719766574589\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"q.head(5)\" outputsMetadata=\"{\\\"0\\\":{\\\"height\\\":196,\\\"type\\\":\\\"dataFrame\\\"}}\"}\n``` python\nq.head(5)\n```\n\n::: {.output .execute_result execution_count=\"24\"}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pronouns</th>\n      <th>review</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>F</td>\n      <td>Good experience for a class online. It was unc...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>Honestly she didnt teach good at all and she w...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>I think if you go by word for word in the modu...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>F</td>\n      <td>Took her online class CSS64. We started buildi...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>F</td>\n      <td>Took her for a late start hybrid class (Bus43)...</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n::: {#b84e3031-d6d0-46e1-8494-2ecc452366a2 .cell .markdown}\nTFIDF vectorization is the process of assigning scores to each review in\na document based on how frequently the word occurs, normalized by how\nfrequently the word occurs in the dataset overall.\n\nWe\\'ll use `TfidfVectorizer()` to generate these scores. This will\nreturn a matrix, with as many rows as reviews, and as many columns as\nwords in our dataset.\n:::\n\n::: {#7ff1b94d-755e-4777-a149-57af7c806207 .cell .code execution_count=\"25\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"10209\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766584798\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"vec = TfidfVectorizer(\n    tokenizer = tokenize,\n    stop_words = list(my_stop_words),\n    ngram_range = (1,4)\n)\nX = vec.fit_transform(q.review)\nfeature_names = vec.get_feature_names_out()\"}\n``` python\nvec = TfidfVectorizer(\n    tokenizer = tokenize,\n    stop_words = list(my_stop_words),\n    ngram_range = (1,4)\n)\nX = vec.fit_transform(q.review)\nfeature_names = vec.get_feature_names_out()\n```\n\n::: {.output .stream .stderr}\n    /home/kantundpeterpan/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n      warnings.warn(\n    /home/kantundpeterpan/miniconda3/envs/nlp/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['anywh', 'becau', 'el', 'elsewh', 'everywh', 'ind', 'otherwi', 'plea', 'somewh'] not in stop_words.\n      warnings.warn(\n:::\n:::\n\n::: {#d9d3d355-64ed-48ef-8bf9-fff922d8477d .cell .code execution_count=\"26\" executionCancelledAt=\"null\" executionTime=\"48\" lastExecutedAt=\"1719766584848\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"feature_names.shape\"}\n``` python\nfeature_names.shape\n```\n\n::: {.output .execute_result execution_count=\"26\"}\n    (365516,)\n:::\n:::\n\n::: {#65c74493-d641-40d9-ba95-f26312642997 .cell .code execution_count=\"27\" executionCancelledAt=\"null\" executionTime=\"53\" lastExecutedAt=\"1719766584901\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"np.random.choice(feature_names, size = 10)\"}\n``` python\nnp.random.choice(feature_names, size = 10)\n```\n\n::: {.output .execute_result execution_count=\"27\"}\n    array(['person liber ideas class', 'lectur tests liter',\n           'devot b.u bit cours', 'kid lectur', 'awesom actual care students',\n           'nice funni hell', 'schedule exam', \"ramblings they'v\",\n           'wish assign', 'text easi follow'], dtype=object)\n:::\n:::\n\n::: {#24a9c568-528c-40b2-b223-0ab06323bddb .cell .markdown}\n`X` is a sparse matrix. We\\'ll now move into filtering X for:\n\n-   Rows with male professors and reviews of high quality\n-   Rows with female professors and reviews of high quality\n-   Rows with male professors and reviews of low quality\n-   Rows with female professors and reviews of low quality\n\nWe can explore feature importance in each of these to get a sense of\nwhich words and phrases are coming up most often in the data.\n:::\n\n::: {#0cb257b4-57ac-4f36-8605-d28cd9beeae0 .cell .code execution_count=\"28\" executionCancelledAt=\"null\" executionTime=\"51\" lastExecutedAt=\"1719766584952\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"m_pos = X[q.pronouns.eq('M') & q.quality.ge(4.5)]\"}\n``` python\nm_pos = X[q.pronouns.eq('M') & q.quality.ge(4.5)]\n```\n:::\n\n::: {#28537a88-8a7e-42c4-ba8b-276532defc87 .cell .code execution_count=\"29\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"52\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766585004\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"m_pos = X[q.pronouns.eq('M') & q.quality.ge(4.5)]\nf_pos = X[q.pronouns.eq('F') & q.quality.ge(4.5)]\nm_neg = X[q.pronouns.eq('M') & q.quality.le(2.5)]\nf_neg = X[q.pronouns.eq('F') & q.quality.le(2.5)]\"}\n``` python\nm_pos = X[q.pronouns.eq('M') & q.quality.ge(4.5)]\nf_pos = X[q.pronouns.eq('F') & q.quality.ge(4.5)]\nm_neg = X[q.pronouns.eq('M') & q.quality.le(2.5)]\nf_neg = X[q.pronouns.eq('F') & q.quality.le(2.5)]\n```\n:::\n\n::: {#57bd3bd1-4eb7-4a35-83d3-3e4c943500f4 .cell .code execution_count=\"30\" executionCancelledAt=\"null\" executionTime=\"51\" lastExecutedAt=\"1719766585056\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"np.unique(np.array(m_pos[0,:].todense()))\"}\n``` python\nnp.unique(np.array(m_pos[0,:].todense()))\n```\n\n::: {.output .execute_result execution_count=\"30\"}\n    array([0.        , 0.04840186, 0.05048048, 0.05840671, 0.0588915 ,\n           0.06440657, 0.07216968, 0.07743822, 0.08628339, 0.0890904 ,\n           0.09454997, 0.09609708, 0.0982585 , 0.09872669, 0.10101388,\n           0.10570444, 0.11337177, 0.12547472, 0.13281775, 0.13699447,\n           0.146295  , 0.15107613, 0.15781475])\n:::\n:::\n\n::: {#c16d09c0-5268-43a0-bfc6-2a1b610b864d .cell .markdown}\nLet\\'s have a look at what language students are using to describe male\nprofessors positively. The code below will return the 300 most important\nngrams.\n:::\n\n::: {#0f03fbae-4024-4c85-b9a5-7924d06af553 .cell .code execution_count=\"31\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"52\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766585108\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"importance = np.argsort(np.asarray(m_pos.sum(axis = 0)))[0,::-1]\nm_pos_features = feature_names[importance[:300]]\"}\n``` python\nimportance = np.argsort(np.asarray(m_pos.sum(axis = 0)))[0,::-1]\nm_pos_features = feature_names[importance[:300]]\n```\n:::\n\n::: {#8bfc99a5-d3f4-46e0-a753-5538e41c0188 .cell .markdown}\nPrint out the 25 most important features\n:::\n\n::: {#2132d526-9676-4a39-b0f6-22af9b72205a .cell .code execution_count=\"32\" executionCancelledAt=\"null\" executionTime=\"52\" lastExecutedAt=\"1719766585161\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"m_pos_features[:25]\"}\n``` python\nm_pos_features[:25]\n```\n\n::: {.output .execute_result execution_count=\"32\"}\n    array(['comment', 'great', 'class', 'teacher', 'best', 'professor',\n           'prof', 'good', 'help', 'realli', 'make', 'easi', 'love',\n           'great teacher', 'awesom', 'know', 'learn', '', 'work', 'lot',\n           'lectur', 'amaz', 'cours', 'nice', 'test'], dtype=object)\n:::\n:::\n\n::: {#07291053-814e-4b40-acdf-e3e415cebef0 .cell .markdown}\nLet\\'s have a look at what language students are using to describe\nfemale professors positively.\n:::\n\n::: {#6cdc8b08-e149-4938-a490-658e336ef797 .cell .code execution_count=\"33\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"52\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719766585213\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"importance = np.argsort(np.asarray(f_pos.sum(axis = 0)))[0,::-1]\nf_pos_features = feature_names[importance[:300]]\nf_pos_features[:25]\"}\n``` python\nimportance = np.argsort(np.asarray(f_pos.sum(axis = 0)))[0,::-1]\nf_pos_features = feature_names[importance[:300]]\nf_pos_features[:25]\n```\n\n::: {.output .execute_result execution_count=\"33\"}\n    array(['comment', 'great', 'class', 'teacher', 'prof', 'help',\n           'professor', 'best', 'good', 'easi', 'realli', 'work', 'nice',\n           'lot', 'love', 'make', 'learn', 'helpful', 'great teacher', '',\n           'amaz', 'great prof', 'cours', 'lectur', 'hard'], dtype=object)\n:::\n:::\n\n::: {#21fed063-8bac-439f-aaa9-1341b81e12c5 .cell .markdown}\nIt should be interesting if there are words exclusively used for one\ngender\n:::\n\n::: {#d466f834-bb0d-4374-a848-42d1f4b8ee8b .cell .code execution_count=\"34\" executionCancelledAt=\"null\" executionTime=\"56\" lastExecutedAt=\"1719766585269\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"#male\nonly_m_pos = ~np.in1d(m_pos_features, f_pos_features)\nm_pos_features[only_m_pos][:25]\"}\n``` python\n#male\nonly_m_pos = ~np.in1d(m_pos_features, f_pos_features)\nm_pos_features[only_m_pos][:25]\n```\n\n::: {.output .stream .stderr}\n    /tmp/ipykernel_1296108/3886134522.py:2: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n      only_m_pos = ~np.in1d(m_pos_features, f_pos_features)\n:::\n\n::: {.output .execute_result execution_count=\"34\"}\n    array(['fantast', 'excel teacher', 'topic', 'awesom professor',\n           'excel professor', 'u', 'brilliant', 'realli enjoy', '2', 'old',\n           'amaz professor', \"professor i'v\", \"teacher i'v\", 'mark', 'b',\n           'hot', 'review', 'genuin', 'bore', \"he'll\", 'reason', 'hours',\n           'want learn', 'overal', 'feel'], dtype=object)\n:::\n:::\n\n::: {#60fc4bc2-acf5-4e0e-8395-0730b97023dc .cell .code execution_count=\"35\" executionCancelledAt=\"null\" executionTime=\"52\" lastExecutedAt=\"1719766585321\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"#female\nonly_f_pos = ~np.in1d(f_pos_features, m_pos_features)\nf_pos_features[only_f_pos][:25]\"}\n``` python\n#female\nonly_f_pos = ~np.isin(f_pos_features, m_pos_features)\nf_pos_features[only_f_pos][:25]\n```\n\n::: {.output .execute_result execution_count=\"35\"}\n    array(['extra credit', 'especi', 'spanish', \"she'll\", 'assignments',\n           'realli nice', 'offer', 'help prof', 'class nice', 'succeed',\n           'realli want', 'alot', 'onlin class', 'knowledgable', 'group',\n           'good lectur', 'attention', 'nice help', \"i'd\", 'real world',\n           'easi grade', 'awsom', 'account', 'guid', 'semester'], dtype=object)\n:::\n:::\n\n::: {#2967b01c-1f56-4fa2-ba7b-300d2dcaeed1 .cell .markdown}\nLet\\'s have a look at what language students are using to describe male\nprofessors negatively.\n:::\n\n::: {#bcc7dfc9-edab-4d8c-9a37-d02aa3549ec7 .cell .code execution_count=\"36\" executionCancelledAt=\"null\" executionTime=\"47\" lastExecutedAt=\"1719766585368\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"importance = np.argsort(np.asarray(m_neg.sum(axis = 0)))[0,::-1]\nm_neg_features = feature_names[importance[:300]]\nm_neg_features[:25]\"}\n``` python\nimportance = np.argsort(np.asarray(m_neg.sum(axis = 0)))[0,::-1]\nm_neg_features = feature_names[importance[:300]]\nm_neg_features[:25]\n```\n\n::: {.output .execute_result execution_count=\"36\"}\n    array(['comment', 'class', 'teach', 'hard', 'test', 'worst', 'professor',\n           'teacher', 'lectur', '', 'time', 'know', 'like', 'grade', \"don't\",\n           \"doesn't\", 'just', 'prof', 'avoid', 'bore', 'question', 'good',\n           'make', 'doe', 'read'], dtype=object)\n:::\n:::\n\n::: {#1d2dc505-ebab-42d4-800e-df381d02ebe4 .cell .markdown}\nLet\\'s have a look at what language students are using to describe\nfemale professors negatively.\n:::\n\n::: {#a970b19e-371d-4e4e-b0e3-b1f4529c40bc .cell .code execution_count=\"37\" executionCancelledAt=\"null\" executionTime=\"57\" lastExecutedAt=\"1719766585425\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"importance = np.argsort(np.asarray(f_neg.sum(axis = 0)))[0,::-1]\nf_neg_features = feature_names[importance[:300]]\nf_neg_features[:25]\"}\n``` python\nimportance = np.argsort(np.asarray(f_neg.sum(axis = 0)))[0,::-1]\nf_neg_features = feature_names[importance[:300]]\nf_neg_features[:25]\n```\n\n::: {.output .execute_result execution_count=\"37\"}\n    array(['comment', 'class', 'worst', 'grade', 'teacher', 'hard', 'teach',\n           \"don't\", \"doesn't\", 'help', 'like', 'test', '', 'just', 'time',\n           'work', 'professor', 'good', 'doe', 'question', 'make', 'know',\n           'horribl', 'learn', 'unclear'], dtype=object)\n:::\n:::\n\n::: {#7fe0f12f-497b-48eb-ae71-8fb034b3f78c .cell .markdown}\nSame analysis for exclusive words:\n:::\n\n::: {#23d3b19e-48bc-40a1-95d7-90b1a62b51d2 .cell .code execution_count=\"38\" executionCancelledAt=\"null\" executionTime=\"52\" lastExecutedAt=\"1719766585477\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"#male\nonly_m_neg = ~np.in1d(m_neg_features, f_neg_features)\nm_neg_features[only_m_neg][:25]\"}\n``` python\n#male\nonly_m_neg = ~np.in1d(m_neg_features, f_neg_features)\nm_neg_features[only_m_neg][:25]\n```\n\n::: {.output .stream .stderr}\n    /tmp/ipykernel_1296108/728473888.py:2: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n      only_m_neg = ~np.in1d(m_neg_features, f_neg_features)\n:::\n\n::: {.output .execute_result execution_count=\"38\"}\n    array(['speak', 'hard understand', 'great', 'arrog', 'hear', 'costs',\n           'smart', 'hardest', 'taught', 'listen', 'rambl', 'english',\n           'exampl', 'let', 'sit', 'incred', 'wrote', 'knowledg', 'possible',\n           'probabl', 'avoid costs', 'gpa', 'offic', '1', \"can't teach\"],\n          dtype=object)\n:::\n:::\n\n::: {#4b9c9575-019a-49bc-8228-500e78d75849 .cell .code execution_count=\"39\" executionCancelledAt=\"null\" executionTime=\"51\" lastExecutedAt=\"1719766585529\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"#female\nonly_f_neg = ~np.in1d(f_neg_features, m_neg_features)\nf_neg_features[only_f_neg][:25]\"}\n``` python\n#female\nonly_f_neg = ~np.in1d(f_neg_features, m_neg_features)\nf_neg_features[only_f_neg][:25]\n```\n\n::: {.output .stream .stderr}\n    /tmp/ipykernel_1296108/1584707764.py:2: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n      only_f_neg = ~np.in1d(f_neg_features, m_neg_features)\n:::\n\n::: {.output .execute_result execution_count=\"39\"}\n    array(['late', 'disorgan', 'gave', 'advis', 'annoy', 'feedback', 'cost',\n           'agre', 'helpful', 'disorganized', 'nice person', 'avoid cost',\n           'unorganized', 'opinion', 'slow', 'quit', 'colleg', 'honestli',\n           'fan', 'papers', 'spanish', 'easi class', 'favorites', 'instead',\n           '5'], dtype=object)\n:::\n:::\n\n::: {#b03ffc57-0591-4762-9d64-1c1bb571fc78 .cell .markdown tags=\"[]\"}\n## Congratulations on making it to the end!\n\n### Where to from here?\n\n-   We can feed these words into Ben Schmidt\\'s\n    [tool](https://benschmidt.org/profGender/#%7B%22database%22%3A%22RMP%22%2C%22plotType%22%3A%22pointchart%22%2C%22method%22%3A%22return_json%22%2C%22search_limits%22%3A%7B%22word%22%3A%5B%22his%20kids%22%2C%22her%20kids%22%5D%2C%22department__id%22%3A%7B%22%24lte%22%3A25%7D%7D%2C%22aesthetic%22%3A%7B%22x%22%3A%22WordsPerMillion%22%2C%22y%22%3A%22department%22%2C%22color%22%3A%22gender%22%7D%2C%22counttype%22%3A%5B%22WordCount%22%2C%22TotalWords%22%5D%2C%22groups%22%3A%5B%22unigram%22%5D%2C%22testGroup%22%3A%22C%22%7D)\n    to derive insights by field.\n-   If you\\'re interested in learning more about [web\n    scraping](https://app.datacamp.com/learn/courses/web-scraping-with-python),\n    take our courses on Web Scraping in Python\n-   If you\\'re intersted in diving in to the world of Natural Language\n    Processing, explore our [skill\n    track](https://app.datacamp.com/learn/skill-tracks/natural-language-processing-in-python).\n:::\n\n::: {#f592331c-f5d8-4c32-8791-2eee74269815 .cell .code execution_count=\"40\" executionCancelledAt=\"null\" executionTime=\"48\" jupyter=\"{\\\"source_hidden\\\":true}\" lastExecutedAt=\"1719766585577\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"import os\nfrom IPython.display import display, HTML\n\n# List files and directories in the current directory\nfiles = os.listdir('.')\n\n# Create an HTML list to display the files\nhtml = \\\"<h1 style='background-color:salmon;text-indent: 1.2em;color:white'>\\\\t Project extension</h1>\\\"\n\n# Display the HTML\ndisplay(HTML(html))\n\" tags=\"[]\"}\n``` python\nimport os\nfrom IPython.display import display, HTML\n\n# List files and directories in the current directory\nfiles = os.listdir('.')\n\n# Create an HTML list to display the files\nhtml = \"<h1 style='background-color:salmon;text-indent: 1.2em;color:white'>\\t Project extension</h1>\"\n\n# Display the HTML\ndisplay(HTML(html))\n```\n\n::: {.output .display_data}\n```{=html}\n<h1 style='background-color:salmon;text-indent: 1.2em;color:white'>\t Project extension</h1>\n```\n:::\n:::\n\n::: {#926249bc-c86b-49bf-8185-ac019aed1f29 .cell .markdown executionCancelledAt=\"null\" executionTime=\"51\" lastExecutedAt=\"1719742508346\" lastExecutedByKernel=\"cbbaf5f6-8a12-4624-8dc7-5134ca7b9994\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"print(', '.join([x.strip() for x in feature_names[importance[:25]]]))\" outputsMetadata=\"{\\\"0\\\":{\\\"height\\\":59,\\\"type\\\":\\\"stream\\\"}}\"}\nUnfortunately Ben Schmidt\\'s tool does not seem to work anymore. So, in\norder to investigate gender bias in this dataset, I came up with the\nfollowing research question: Is the sentiment of the review associated\nwith the use of stereotypical words for the two genders?\n\nIn order to answer that question, I looked for a lexicon that I could\nscreen the reviews against. While I found some (a lot!) papers\naddressing detection of gender stereotypes using NLP, I could not find\nsaid lexicon - but I foudn that Language Models based on word embeddings\nalso learn the gender bias implicit in the corpus they are trained on.\n\nSo I figured that maybe it would be possible to exploit that to\nconstruct - in a quick and dirty kind of fashion - this lexicon myself\nby asking Google\\'s GEMINI. Some prompt engineering was necessary: [you\ncan have a look for\nyourself](%5Burl%5D(https://g.co/gemini/share/db15535c30d9)).\nIronically, Gemini seemed more hesitant to compile a list of words\nstereotypically negatively associated with women than for men.\n:::\n\n::: {#74757c90-faf4-49db-beeb-b54a761abc0f .cell .markdown}\nLet\\'s parse those lists:\n:::\n\n::: {#886fdf04-c004-4172-839d-743eaea1a976 .cell .code execution_count=\"41\" executionCancelledAt=\"null\" executionTime=\"47\" lastExecutedAt=\"1719766585624\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"def parse_gemini_list(s: str) -> list:\n    \\\"\\\"\\\"parse comma separated list of words remove annotations in parentheses\\\"\\\"\\\"\n    new = [w.strip() for w in s.split(',')]\n    for i,n in enumerate(new):\n        if '(' in n:\n            new[i] = n.split('(')[0]\n            \n    return new\"}\n``` python\ndef parse_gemini_list(s: str) -> list:\n    \"\"\"parse comma separated list of words remove annotations in parentheses\"\"\"\n    new = [w.strip() for w in s.split(',')]\n    for i,n in enumerate(new):\n        if '(' in n:\n            new[i] = n.split('(')[0]\n    \n    new = np.unique([x for word in new for x in tokenize(word)])\n            \n    return new\n```\n:::\n\n::: {#bd994153-eea1-4475-9778-8753e3cc5d38 .cell .code execution_count=\"42\" collapsed=\"false\" executionCancelledAt=\"null\" executionTime=\"17\" jupyter=\"{\\\"outputs_hidden\\\":false,\\\"source_hidden\\\":false}\" lastExecutedAt=\"1719767634723\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"with open('w_pos_lex', 'r') as f:\n    w_pos_lex = parse_gemini_list(f.read())\nw_pos_ex = np.unique([tokenize(word) for word in w_pos_lex])\"}\n``` python\nwith open('w_pos_lex', 'r') as f:\n    w_pos_lex = parse_gemini_list(f.read())\n```\n:::\n\n::: {#9f9d135a-d7ab-4bd8-a2cc-e616cd1fb1e3 .cell .code execution_count=\"43\" executionCancelledAt=\"null\" executionTime=\"12\" lastExecutedAt=\"1719767635017\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"with open('w_neg_lex', 'r') as f:\n    w_neg_lex = parse_gemini_list(f.read())\"}\n``` python\nwith open('w_neg_lex', 'r') as f:\n    w_neg_lex = parse_gemini_list(f.read())\n```\n:::\n\n::: {#df1fddda-6d00-4913-8442-02fb87632afa .cell .code execution_count=\"44\" executionCancelledAt=\"null\" executionTime=\"12\" lastExecutedAt=\"1719767487043\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"with open('m_pos_lex', 'r') as f:\n    m_pos_lex = parse_gemini_list(f.read())\"}\n``` python\nwith open('m_pos_lex', 'r') as f:\n    m_pos_lex = parse_gemini_list(f.read())\n```\n:::\n\n::: {#b88b5fe3-ee53-4bde-808b-cc733c985ee4 .cell .code execution_count=\"45\" executionCancelledAt=\"null\" executionTime=\"11\" lastExecutedAt=\"1719767488680\" lastExecutedByKernel=\"f6c43d9d-c556-42d8-9544-e49e4eaa9fbc\" lastScheduledRunId=\"null\" lastSuccessfullyExecutedCode=\"with open('m_neg_lex', 'r') as f:\n    m_neg_lex = parse_gemini_list(f.read())\"}\n``` python\nwith open('m_neg_lex', 'r') as f:\n    m_neg_lex = parse_gemini_list(f.read())\n```\n:::\n\n::: {#e1d0d731-080b-41d6-a61c-2ec7265bf2b8 .cell .code execution_count=\"46\"}\n``` python\nw_pos_lex_uni = w_pos_lex[~np.isin(w_pos_lex, m_pos_lex)]\n```\n:::\n\n::: {#3180b223-eac0-439d-8404-a8a8ed08d18e .cell .code execution_count=\"47\"}\n``` python\nm_pos_lex_uni = m_pos_lex[~np.isin(m_pos_lex, w_pos_lex)]\n```\n:::\n\n::: {#edff4a40-9c8a-49c5-8eea-2790c56455f8 .cell .code execution_count=\"48\"}\n``` python\nw_neg_lex_uni = w_neg_lex[~np.isin(w_neg_lex, m_neg_lex)]\n```\n:::\n\n::: {#c7830185-e05a-4e69-bf5d-628d81aca519 .cell .code execution_count=\"49\"}\n``` python\nm_neg_lex_uni = m_neg_lex[~np.isin(m_neg_lex, w_neg_lex)]\n```\n:::\n\n::: {#2329a767-54d7-42d8-b6f3-933573401bcf .cell .code execution_count=\"50\"}\n``` python\nq.head(5)\n```\n\n::: {.output .execute_result execution_count=\"50\"}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pronouns</th>\n      <th>review</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>F</td>\n      <td>Good experience for a class online. It was unc...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>Honestly she didnt teach good at all and she w...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>I think if you go by word for word in the modu...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>F</td>\n      <td>Took her online class CSS64. We started buildi...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>F</td>\n      <td>Took her for a late start hybrid class (Bus43)...</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n::: {#83c2523b-7fce-4eee-990a-dc868b299f80 .cell .code execution_count=\"51\"}\n``` python\nstereo_count_w_pos = q.loc[q.pronouns.eq('F') & q.quality.ge(4.5)].review.apply(tokenize).apply(\n    np.isin, args = (w_pos_lex_uni,)).apply(np.sum)\n```\n:::\n\n::: {#dedefea8-066b-4599-82b8-baf576b9ceb2 .cell .code execution_count=\"52\"}\n``` python\ndist_w_pos = stereo_count_w_pos.value_counts()\ndist_w_pos.plot(kind = 'bar')\n```\n\n::: {.output .execute_result execution_count=\"52\"}\n    <Axes: xlabel='review'>\n:::\n\n::: {.output .display_data}\n![](a30be157278c611b81dac535878126254cbd38c4.png)\n:::\n:::\n\n::: {#a72366d9-2b2f-4001-b485-158fd1002683 .cell .code execution_count=\"53\"}\n``` python\nstereo_count_m_pos = q.loc[q.pronouns.eq('M') & q.quality.ge(4.5)].review.apply(tokenize).apply(\n    np.isin, args = (m_pos_lex_uni,)).apply(np.sum)\n```\n:::\n\n::: {#aa666a50-7194-47b8-8fa2-8e1ae738617e .cell .code execution_count=\"54\"}\n``` python\ndist_m_pos = stereo_count_m_pos.value_counts()\n```\n:::\n\n::: {#3056b449-58cd-4267-8748-b9da93ec02a8 .cell .code execution_count=\"55\"}\n``` python\ndist_m_pos.plot(kind = 'bar')\n```\n\n::: {.output .execute_result execution_count=\"55\"}\n    <Axes: xlabel='review'>\n:::\n\n::: {.output .display_data}\n![](b6e92ef6593beea9b56ab9d71eb2fb77a43ab38c.png)\n:::\n:::\n\n::: {#22c92288-d2e8-4461-85b9-46ac66942121 .cell .code execution_count=\"56\"}\n``` python\nstereo_count_w_neg = q.loc[q.pronouns.eq('F') & q.quality.le(2.5)].review.apply(tokenize).apply(\n    np.isin, args = (w_neg_lex_uni,)).apply(np.sum)\n```\n:::\n\n::: {#a1d8e3ad-c3ff-48a8-91b9-12f6ee868d8b .cell .code execution_count=\"57\"}\n``` python\ndist_w_neg = stereo_count_w_neg.value_counts().sort_index()\n```\n:::\n\n::: {#93cb893f-c994-4a57-8332-1ae75ac34036 .cell .code execution_count=\"58\"}\n``` python\ndist_w_neg.plot(kind = 'bar')\n```\n\n::: {.output .execute_result execution_count=\"58\"}\n    <Axes: xlabel='review'>\n:::\n\n::: {.output .display_data}\n![](716d8820669c745bee14fcd674b1c41bde1dc9ba.png)\n:::\n:::\n\n::: {#fe5a75f6-143c-4da3-9973-11260c8517db .cell .code execution_count=\"59\"}\n``` python\nstereo_count_m_neg = q.loc[q.pronouns.eq('M') & q.quality.le(2.5)].review.apply(tokenize).apply(\n    np.isin, args = (m_neg_lex_uni,)).apply(np.sum)\n```\n:::\n\n::: {#c5f73dec-197b-4499-a1c6-375c97b599c8 .cell .code execution_count=\"60\"}\n``` python\ndist_m_neg = stereo_count_m_neg.value_counts()\n```\n:::\n\n::: {#c8b85d84-388b-43e0-a74e-4fc1d5b3ddc7 .cell .code execution_count=\"61\"}\n``` python\ndist_m_neg.plot(kind = 'bar')\n```\n\n::: {.output .execute_result execution_count=\"61\"}\n    <Axes: xlabel='review'>\n:::\n\n::: {.output .display_data}\n![](f33bb3632229bcf556062872eb457d333de722d1.png)\n:::\n:::\n\n::: {#bc30f7ed-aa4b-49cd-b8b6-a3f904ead4bc .cell .code execution_count=\"62\"}\n``` python\ndist_m_neg\n```\n\n::: {.output .execute_result execution_count=\"62\"}\n    review\n    0    2218\n    1     240\n    2      37\n    3      10\n    4       9\n    5       1\n    Name: count, dtype: int64\n:::\n:::\n\n::: {#7dc12035-ad18-4b76-9ae1-f8e6f1b71836 .cell .code execution_count=\"63\"}\n``` python\nfrom scipy.stats import chi2_contingency\n```\n:::\n\n::: {#d22b9ce5-724f-4702-b984-fe3743e01b4e .cell .code execution_count=\"64\"}\n``` python\ntable = np.zeros((2,  max(dist_w_neg.shape[0], dist_m_neg.shape[0])), dtype = int)\ntable[0, :dist_w_neg.shape[0]] = dist_w_neg.values\ntable[1, :dist_m_neg.shape[0]] = dist_m_neg.values\n```\n:::\n\n::: {#c00206dd-8b13-4c2e-b639-08000509c17a .cell .code execution_count=\"65\"}\n``` python\ntable\n```\n\n::: {.output .execute_result execution_count=\"65\"}\n    array([[ 278,  229,  146,   86,   37,   20,    3,    1,    1],\n           [2218,  240,   37,   10,    9,    1,    0,    0,    0]])\n:::\n:::\n\n::: {#2fb4f434-9de7-4794-9294-fc9d00028706 .cell .code execution_count=\"66\"}\n``` python\nchi2_table = pd.DataFrame(table, index = ['F', 'M'])\n```\n:::\n\n::: {#3a6adb10-2f71-44a8-a9ab-1b1cb310d120 .cell .code execution_count=\"67\"}\n``` python\nchi2_table\n```\n\n::: {.output .execute_result execution_count=\"67\"}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>F</th>\n      <td>278</td>\n      <td>229</td>\n      <td>146</td>\n      <td>86</td>\n      <td>37</td>\n      <td>20</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>M</th>\n      <td>2218</td>\n      <td>240</td>\n      <td>37</td>\n      <td>10</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n::: {#ae2235ff-ce83-4aa6-b581-65b1be3c7693 .cell .code execution_count=\"68\"}\n``` python\nchi2_contingency(chi2_table)\n```\n\n::: {.output .execute_result execution_count=\"68\"}\n    Chi2ContingencyResult(statistic=np.float64(1073.2259818314606), pvalue=np.float64(2.3184709261716882e-226), dof=8, expected_freq=array([[6.02924005e+02, 1.13289807e+02, 4.42047648e+01, 2.31893848e+01,\n            1.11115802e+01, 5.07267793e+00, 7.24668275e-01, 2.41556092e-01,\n            2.41556092e-01],\n           [1.89307600e+03, 3.55710193e+02, 1.38795235e+02, 7.28106152e+01,\n            3.48884198e+01, 1.59273221e+01, 2.27533172e+00, 7.58443908e-01,\n            7.58443908e-01]]))\n:::\n:::\n\n::: {#08caeb59-fc5d-42f4-8ffe-d99ff05e50cf .cell .code execution_count=\"69\"}\n``` python\ntable = np.zeros((2, max(dist_w_pos.shape[0], dist_m_pos.shape[0])), dtype = int)\ntable[0, :dist_w_pos.shape[0]] = dist_w_pos.values\ntable[1, :dist_m_pos.shape[0]] = dist_m_pos.values\n```\n:::\n\n::: {#9a303cdb-e2ea-4435-80f0-896b80d41aae .cell .code execution_count=\"70\"}\n``` python\nchi2_table = pd.DataFrame(table, index = ['F', 'M'])\n```\n:::\n\n::: {#1b671b41-4db7-4b29-872d-6c035505a7c8 .cell .code execution_count=\"71\"}\n``` python\nchi2_contingency(chi2_table)\n```\n\n::: {.output .execute_result execution_count=\"71\"}\n    Chi2ContingencyResult(statistic=np.float64(35.680653072523995), pvalue=np.float64(1.1002520334386392e-06), dof=5, expected_freq=array([[6.76990876e+02, 2.24479927e+02, 6.08759124e+01, 9.13138686e+00,\n            1.26824818e+00, 2.53649635e-01],\n           [1.99200912e+03, 6.60520073e+02, 1.79124088e+02, 2.68686131e+01,\n            3.73175182e+00, 7.46350365e-01]]))\n:::\n:::\n\n::: {#ec11f468-ca39-4eff-a68b-b9f593fa3831 .cell .code}\n``` python\n```\n:::\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"notebook.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.54","theme":"spacelab"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}